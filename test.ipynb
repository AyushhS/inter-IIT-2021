{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output = pd.DataFrame(columns=['frame num','person id','bb_xmin','bb_ymin','bb_height','bb_width','age_min','age_max','age_actual','gender'])\n",
    "\n",
    "# loading required models/frameworks\n",
    "facedetector = MTCNN()\n",
    "age_model = tf.keras.models.load_model('Age_model')\n",
    "gender_model = tf.keras.models.load_model('Gender_model')\n",
    "\n",
    "# File handling\n",
    "Videopath = str(sys.argv[1])\n",
    "outputfolder = []\n",
    "if len(sys.argv) == 1:\n",
    "    os.mkdir('output')\n",
    "    outputfolder = 'output'\n",
    "else:\n",
    "    if os.path.isdir(sys.argv[2]) == True:\n",
    "        outputfolder = sys.argv[2]\n",
    "    else:\n",
    "        outputfolder = os.mkdir(sys.argv[2])\n",
    "if os.path.isfile(Videopath) == True:\n",
    "    videos = [Videopath]\n",
    "else:\n",
    "    videos = [Videopath + '\\\\' + i for i in os.listdir(Videopath)]\n",
    "\n",
    "print(videos)\n",
    "# Video Processing\n",
    "for video in videos:\n",
    "\n",
    "    # Taking in individual videos\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    out = cv2.VideoWriter(outputfolder + '\\\\' + video.split('\\\\')[-1].split('.')[0] + '_output' + video.split('\\\\')[-1].split('.')[1], cv2.VideoWriter_fourcc(*'MJPG'), cap.get(cv2.CAP_PROP_FPS), (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    # Processing\n",
    "    framenumber = 1\n",
    "    while framenumber < 30:\n",
    "        ret, image = cap.read()\n",
    "\n",
    "        if ret == True:\n",
    "            print('at frame = ', framenumber, '\\n')\n",
    "            # Detecting Faces\n",
    "            faces = facedetector.detect_faces(image)\n",
    "            if faces == []:\n",
    "                cv2.imshow('img', image)\n",
    "                framenumber += 1\n",
    "                continue;\n",
    "\n",
    "            # Drawing boxes and detecting age and gender\n",
    "            ID = 0\n",
    "            image2 = image.copy()\n",
    "            for face in faces:\n",
    "                (x, y, w, h) = face['box']\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                face = image2[y:y+h,x:x+w]\n",
    "                face = cv2.resize(face, (48,48))\n",
    "                face = face.reshape(1, 48, 48, 3)\n",
    "                #plt.imshow(face[0])\n",
    "                ID += 1\n",
    "                predicted_age_actual = age_model.predict(face)\n",
    "                predicted_age_min = int(predicted_age_actual / 10) * 10\n",
    "                predicted_age_max = predicted_age_min + 10\n",
    "                gp = gender_model.predict(face)\n",
    "                if (gp[0][1] > gp[0][0]):\n",
    "                    predicted_gender = 'M'\n",
    "                else:\n",
    "                    predicted_gender = 'F'\n",
    "                cv2.putText(image, str(predicted_gender) + ',' + str(predicted_age_min) + ' - ' + str(predicted_age_max), (x, y), cv2.FONT_HERSHEY_PLAIN, 1, (255,0,0), 1)\n",
    "\n",
    "                newrow = [{\n",
    "                    'frame num':framenumber,\n",
    "                    'person id':ID,\n",
    "                    'bb_xmin':x,\n",
    "                    'bb_ymin':y,\n",
    "                    'bb_height':h,\n",
    "                    'bb_width':w,\n",
    "                    'age_min':predicted_age_min,\n",
    "                    'age_max':predicted_age_max,\n",
    "                    'age_actual':predicted_age_actual,\n",
    "                    'gender':predicted_gender\n",
    "                }]\n",
    "                output = output.append(newrow)\n",
    "\n",
    "            framenumber += 1\n",
    "\n",
    "            cv2.imshow('img', image)\n",
    "            out.write(image)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    output.to_csv(outputfolder + '\\\\' + video.split('\\\\')[-1].split('.')[0] + '_output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76a1c8c3fd934dbaf561da1caa52d85ab6f51e4fd4d989b33244b0dc867a8076"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
